# Comparing `tmp/ts_sdk-2.0.0rc4-py3-none-any.whl.zip` & `tmp/ts_sdk-2.0.0rc5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,94 +1,94 @@
-Zip file size: 91469 bytes, number of entries: 92
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-19 12:50 __tests__/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-19 12:50 __tests__/unit/__init__.py
--rw-r--r--  2.0 unx     4709 b- defN 23-Apr-19 12:50 __tests__/unit/test_allowed_ids.py
--rw-r--r--  2.0 unx     1471 b- defN 23-Apr-19 12:50 __tests__/unit/test_cli_put.py
--rw-r--r--  2.0 unx     2466 b- defN 23-Apr-19 12:50 __tests__/unit/test_command.py
--rw-r--r--  2.0 unx    31533 b- defN 23-Apr-19 12:50 __tests__/unit/test_context.py
--rw-r--r--  2.0 unx     9218 b- defN 23-Apr-19 12:50 __tests__/unit/test_datalake.py
--rw-r--r--  2.0 unx     1628 b- defN 23-Apr-19 12:50 __tests__/unit/test_encoders.py
--rw-r--r--  2.0 unx     2161 b- defN 23-Apr-19 12:50 __tests__/unit/test_es_datalake.py
--rw-r--r--  2.0 unx     4307 b- defN 23-Apr-19 12:50 __tests__/unit/test_fileinfo.py
--rw-r--r--  2.0 unx      939 b- defN 23-Apr-19 12:50 __tests__/unit/test_merge.py
--rw-r--r--  2.0 unx     1200 b- defN 23-Apr-19 12:50 __tests__/unit/test_run_reuse.py
--rw-r--r--  2.0 unx     3552 b- defN 23-Apr-19 12:50 __tests__/unit/test_task.py
--rw-r--r--  2.0 unx      660 b- defN 23-Apr-19 12:50 __tests__/unit/test_taskdev.py
--rw-r--r--  2.0 unx    13747 b- defN 23-Apr-19 12:50 __tests__/unit/test_util_log.py
--rw-r--r--  2.0 unx     7328 b- defN 23-Apr-19 12:50 __tests__/unit/test_util_validation.py
--rw-r--r--  2.0 unx     1091 b- defN 23-Apr-19 12:50 __tests__/unit/test_versioned_ref.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-19 12:50 __tests__/unit/task/__init__.py
--rw-r--r--  2.0 unx     1149 b- defN 23-Apr-19 12:50 __tests__/unit/task/test_decorators.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-19 12:50 __tests__/unit/task/adapters/__init__.py
--rw-r--r--  2.0 unx     4988 b- defN 23-Apr-19 12:50 __tests__/unit/task/adapters/test_adapters.py
--rw-r--r--  2.0 unx     1329 b- defN 23-Apr-19 12:50 __tests__/unit/task/adapters/test_curry_version.py
--rw-r--r--  2.0 unx     2625 b- defN 23-Apr-19 12:50 __tests__/unit/task/adapters/test_platform_version.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-19 12:50 __tests__/unit/task/log_codes/__init__.py
--rw-r--r--  2.0 unx     2230 b- defN 23-Apr-19 12:50 __tests__/unit/task/log_codes/test_log_code_collection_meta.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-19 12:50 __tests__/unit/task/snapshots/__init__.py
--rw-r--r--  2.0 unx     2563 b- defN 23-Apr-19 12:50 __tests__/unit/task/snapshots/snap_test_util_log.py
--rw-r--r--  2.0 unx      183 b- defN 23-Apr-19 12:50 ts_sdk/__init__.py
--rw-r--r--  2.0 unx     2877 b- defN 23-Apr-19 12:50 ts_sdk/cli/__api.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-19 12:50 ts_sdk/cli/__init__.py
--rw-r--r--  2.0 unx     2173 b- defN 23-Apr-19 12:50 ts_sdk/cli/__init_cmd.py
--rw-r--r--  2.0 unx     1188 b- defN 23-Apr-19 12:50 ts_sdk/cli/__main__.py
--rw-r--r--  2.0 unx     7681 b- defN 23-Apr-19 12:50 ts_sdk/cli/__put_cmd.py
--rw-r--r--  2.0 unx     2442 b- defN 23-Apr-19 12:50 ts_sdk/cli/__utils.py
--rw-r--r--  2.0 unx       63 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/protocol/README.md.template
--rw-r--r--  2.0 unx      712 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/protocol/protocol.json.template
--rw-r--r--  2.0 unx      874 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/protocol/script.js.template
--rw-r--r--  2.0 unx      246 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/task-script/Pipfile
--rw-r--r--  2.0 unx       72 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/task-script/README.md.template
--rw-r--r--  2.0 unx      113 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/task-script/config.json
--rw-r--r--  2.0 unx     1490 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/task-script/main.py
--rw-r--r--  2.0 unx      442 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/task-script/__test__/test_business_logic.py
--rw-r--r--  2.0 unx      745 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/task-script/__test__/test_config.py
--rw-r--r--  2.0 unx      681 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/task-script/__test__/test_integration.py
--rw-r--r--  2.0 unx       35 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/task-script/__test__/data/expected.json
--rw-r--r--  2.0 unx       15 b- defN 23-Apr-19 12:50 ts_sdk/cli/protocol-template/task-script/__test__/data/input.json
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-19 12:50 ts_sdk/cli/put_cmd_helpers/__init__.py
--rw-r--r--  2.0 unx     1740 b- defN 23-Apr-19 12:50 ts_sdk/cli/put_cmd_helpers/upload_validator.py
--rw-r--r--  2.0 unx      270 b- defN 23-Apr-19 12:50 ts_sdk/schemas/__init__.py
--rw-r--r--  2.0 unx     1766 b- defN 23-Apr-19 12:50 ts_sdk/schemas/config.schema.json
--rw-r--r--  2.0 unx     2206 b- defN 23-Apr-19 12:50 ts_sdk/schemas/protocol.schema.json
--rw-r--r--  2.0 unx      104 b- defN 23-Apr-19 12:50 ts_sdk/task/__init__.py
--rw-r--r--  2.0 unx    25471 b- defN 23-Apr-19 12:50 ts_sdk/task/__task_script_runner.py
--rw-r--r--  2.0 unx     3317 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_command.py
--rw-r--r--  2.0 unx     6782 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_config.py
--rw-r--r--  2.0 unx    28789 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_datalake.py
--rw-r--r--  2.0 unx     1252 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_decorators.py
--rw-r--r--  2.0 unx     1714 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_es_datalake.py
--rw-r--r--  2.0 unx     5630 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_fileinfo.py
--rw-r--r--  2.0 unx     2221 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_ids.py
--rw-r--r--  2.0 unx     8334 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_log.py
--rw-r--r--  2.0 unx      917 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_merge.py
--rw-r--r--  2.0 unx     1483 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_metadata.py
--rw-r--r--  2.0 unx      827 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_storage.py
--rw-r--r--  2.0 unx     5534 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_validation.py
--rw-r--r--  2.0 unx     1391 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_versioned_ref.py
--rw-r--r--  2.0 unx      677 b- defN 23-Apr-19 12:50 ts_sdk/task/__validate_config.py
--rw-r--r--  2.0 unx     1925 b- defN 23-Apr-19 12:50 ts_sdk/task/data_model.py
--rw-r--r--  2.0 unx      669 b- defN 23-Apr-19 12:50 ts_sdk/task/encoders.py
--rw-r--r--  2.0 unx     1742 b- defN 23-Apr-19 12:50 ts_sdk/task/run.py
--rw-r--r--  2.0 unx     5183 b- defN 23-Apr-19 12:50 ts_sdk/task/run_reuse_loop.py
--rw-r--r--  2.0 unx      295 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_adapters/__init__.py
--rw-r--r--  2.0 unx     2175 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_adapters/communication_format.py
--rw-r--r--  2.0 unx      656 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_adapters/curry_format.py
--rw-r--r--  2.0 unx     1193 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_adapters/endpoint_adapter.py
--rw-r--r--  2.0 unx     2892 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_adapters/make_adapter.py
--rw-r--r--  2.0 unx     4657 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_task/__init__.py
--rw-r--r--  2.0 unx      108 b- defN 23-Apr-19 12:50 ts_sdk/task/__util_task/exceptions.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-19 12:50 ts_sdk/task/log_codes/__init__.py
--rw-r--r--  2.0 unx      178 b- defN 23-Apr-19 12:50 ts_sdk/task/log_codes/log_code.py
--rw-r--r--  2.0 unx     1831 b- defN 23-Apr-19 12:50 ts_sdk/task/log_codes/log_code_collection.py
--rw-r--r--  2.0 unx     4348 b- defN 23-Apr-19 12:50 ts_sdk/task/log_codes/log_code_collection_meta.py
--rw-r--r--  2.0 unx     1967 b- defN 23-Apr-19 12:50 ts_sdk/task/log_codes/log_code_validator.py
--rw-r--r--  2.0 unx      106 b- defN 23-Apr-19 12:50 ts_sdk/taskdev/__init__.py
--rw-r--r--  2.0 unx     5255 b- defN 23-Apr-19 12:50 ts_sdk/taskdev/context.py
--rw-r--r--  2.0 unx     1502 b- defN 23-Apr-19 12:50 ts_sdk/taskdev/testing.py
--rw-r--r--  2.0 unx    11370 b- defN 23-Apr-19 12:50 ts_sdk-2.0.0rc4.dist-info/LICENSE.txt
--rw-r--r--  2.0 unx     8636 b- defN 23-Apr-19 12:50 ts_sdk-2.0.0rc4.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-19 12:50 ts_sdk-2.0.0rc4.dist-info/WHEEL
--rw-r--r--  2.0 unx       52 b- defN 23-Apr-19 12:50 ts_sdk-2.0.0rc4.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       17 b- defN 23-Apr-19 12:50 ts_sdk-2.0.0rc4.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     8507 b- defN 23-Apr-19 12:50 ts_sdk-2.0.0rc4.dist-info/RECORD
-92 files, 288707 bytes uncompressed, 77707 bytes compressed:  73.1%
+Zip file size: 92898 bytes, number of entries: 92
+-rw-r--r--  2.0 unx        0 b- defN 23-May-15 19:26 __tests__/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-15 19:26 __tests__/unit/__init__.py
+-rw-r--r--  2.0 unx     4810 b- defN 23-May-15 19:26 __tests__/unit/test_allowed_ids.py
+-rw-r--r--  2.0 unx     2945 b- defN 23-May-15 19:26 __tests__/unit/test_cli_put.py
+-rw-r--r--  2.0 unx     2466 b- defN 23-May-15 19:26 __tests__/unit/test_command.py
+-rw-r--r--  2.0 unx    36619 b- defN 23-May-15 19:26 __tests__/unit/test_context.py
+-rw-r--r--  2.0 unx     9218 b- defN 23-May-15 19:26 __tests__/unit/test_datalake.py
+-rw-r--r--  2.0 unx     1628 b- defN 23-May-15 19:26 __tests__/unit/test_encoders.py
+-rw-r--r--  2.0 unx     2161 b- defN 23-May-15 19:26 __tests__/unit/test_es_datalake.py
+-rw-r--r--  2.0 unx     5153 b- defN 23-May-15 19:26 __tests__/unit/test_fileinfo.py
+-rw-r--r--  2.0 unx      939 b- defN 23-May-15 19:26 __tests__/unit/test_merge.py
+-rw-r--r--  2.0 unx     1200 b- defN 23-May-15 19:26 __tests__/unit/test_run_reuse.py
+-rw-r--r--  2.0 unx     3552 b- defN 23-May-15 19:26 __tests__/unit/test_task.py
+-rw-r--r--  2.0 unx      660 b- defN 23-May-15 19:26 __tests__/unit/test_taskdev.py
+-rw-r--r--  2.0 unx    13747 b- defN 23-May-15 19:26 __tests__/unit/test_util_log.py
+-rw-r--r--  2.0 unx     7639 b- defN 23-May-15 19:26 __tests__/unit/test_util_validation.py
+-rw-r--r--  2.0 unx     1091 b- defN 23-May-15 19:26 __tests__/unit/test_versioned_ref.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-15 19:26 __tests__/unit/task/__init__.py
+-rw-r--r--  2.0 unx     1149 b- defN 23-May-15 19:26 __tests__/unit/task/test_decorators.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-15 19:26 __tests__/unit/task/adapters/__init__.py
+-rw-r--r--  2.0 unx     4988 b- defN 23-May-15 19:26 __tests__/unit/task/adapters/test_adapters.py
+-rw-r--r--  2.0 unx     1329 b- defN 23-May-15 19:26 __tests__/unit/task/adapters/test_curry_version.py
+-rw-r--r--  2.0 unx     2625 b- defN 23-May-15 19:26 __tests__/unit/task/adapters/test_platform_version.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-15 19:26 __tests__/unit/task/log_codes/__init__.py
+-rw-r--r--  2.0 unx     2230 b- defN 23-May-15 19:26 __tests__/unit/task/log_codes/test_log_code_collection_meta.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-15 19:26 __tests__/unit/task/snapshots/__init__.py
+-rw-r--r--  2.0 unx     2563 b- defN 23-May-15 19:26 __tests__/unit/task/snapshots/snap_test_util_log.py
+-rw-r--r--  2.0 unx      183 b- defN 23-May-15 19:26 ts_sdk/__init__.py
+-rw-r--r--  2.0 unx     2877 b- defN 23-May-15 19:26 ts_sdk/cli/__api.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-15 19:26 ts_sdk/cli/__init__.py
+-rw-r--r--  2.0 unx     2173 b- defN 23-May-15 19:26 ts_sdk/cli/__init_cmd.py
+-rw-r--r--  2.0 unx     1188 b- defN 23-May-15 19:26 ts_sdk/cli/__main__.py
+-rw-r--r--  2.0 unx     7736 b- defN 23-May-15 19:26 ts_sdk/cli/__put_cmd.py
+-rw-r--r--  2.0 unx     2442 b- defN 23-May-15 19:26 ts_sdk/cli/__utils.py
+-rw-r--r--  2.0 unx       63 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/protocol/README.md.template
+-rw-r--r--  2.0 unx      712 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/protocol/protocol.json.template
+-rw-r--r--  2.0 unx      874 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/protocol/script.js.template
+-rw-r--r--  2.0 unx      246 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/task-script/Pipfile
+-rw-r--r--  2.0 unx       72 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/task-script/README.md.template
+-rw-r--r--  2.0 unx      113 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/task-script/config.json
+-rw-r--r--  2.0 unx     1490 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/task-script/main.py
+-rw-r--r--  2.0 unx      442 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/task-script/__test__/test_business_logic.py
+-rw-r--r--  2.0 unx      745 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/task-script/__test__/test_config.py
+-rw-r--r--  2.0 unx      681 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/task-script/__test__/test_integration.py
+-rw-r--r--  2.0 unx       35 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/task-script/__test__/data/expected.json
+-rw-r--r--  2.0 unx       15 b- defN 23-May-15 19:26 ts_sdk/cli/protocol-template/task-script/__test__/data/input.json
+-rw-r--r--  2.0 unx        0 b- defN 23-May-15 19:26 ts_sdk/cli/put_cmd_helpers/__init__.py
+-rw-r--r--  2.0 unx     1740 b- defN 23-May-15 19:26 ts_sdk/cli/put_cmd_helpers/upload_validator.py
+-rw-r--r--  2.0 unx      270 b- defN 23-May-15 19:26 ts_sdk/schemas/__init__.py
+-rw-r--r--  2.0 unx     1766 b- defN 23-May-15 19:26 ts_sdk/schemas/config.schema.json
+-rw-r--r--  2.0 unx     2206 b- defN 23-May-15 19:26 ts_sdk/schemas/protocol.schema.json
+-rw-r--r--  2.0 unx      104 b- defN 23-May-15 19:26 ts_sdk/task/__init__.py
+-rw-r--r--  2.0 unx    27651 b- defN 23-May-15 19:26 ts_sdk/task/__task_script_runner.py
+-rw-r--r--  2.0 unx     3317 b- defN 23-May-15 19:26 ts_sdk/task/__util_command.py
+-rw-r--r--  2.0 unx     6998 b- defN 23-May-15 19:26 ts_sdk/task/__util_config.py
+-rw-r--r--  2.0 unx    28883 b- defN 23-May-15 19:26 ts_sdk/task/__util_datalake.py
+-rw-r--r--  2.0 unx     1613 b- defN 23-May-15 19:26 ts_sdk/task/__util_decorators.py
+-rw-r--r--  2.0 unx     1714 b- defN 23-May-15 19:26 ts_sdk/task/__util_es_datalake.py
+-rw-r--r--  2.0 unx     5685 b- defN 23-May-15 19:26 ts_sdk/task/__util_fileinfo.py
+-rw-r--r--  2.0 unx     2221 b- defN 23-May-15 19:26 ts_sdk/task/__util_ids.py
+-rw-r--r--  2.0 unx     8334 b- defN 23-May-15 19:26 ts_sdk/task/__util_log.py
+-rw-r--r--  2.0 unx      917 b- defN 23-May-15 19:26 ts_sdk/task/__util_merge.py
+-rw-r--r--  2.0 unx     1483 b- defN 23-May-15 19:26 ts_sdk/task/__util_metadata.py
+-rw-r--r--  2.0 unx      827 b- defN 23-May-15 19:26 ts_sdk/task/__util_storage.py
+-rw-r--r--  2.0 unx     6429 b- defN 23-May-15 19:26 ts_sdk/task/__util_validation.py
+-rw-r--r--  2.0 unx     1391 b- defN 23-May-15 19:26 ts_sdk/task/__util_versioned_ref.py
+-rw-r--r--  2.0 unx      677 b- defN 23-May-15 19:26 ts_sdk/task/__validate_config.py
+-rw-r--r--  2.0 unx     1925 b- defN 23-May-15 19:26 ts_sdk/task/data_model.py
+-rw-r--r--  2.0 unx      669 b- defN 23-May-15 19:26 ts_sdk/task/encoders.py
+-rw-r--r--  2.0 unx     1742 b- defN 23-May-15 19:26 ts_sdk/task/run.py
+-rw-r--r--  2.0 unx     5373 b- defN 23-May-15 19:26 ts_sdk/task/run_reuse_loop.py
+-rw-r--r--  2.0 unx      295 b- defN 23-May-15 19:26 ts_sdk/task/__util_adapters/__init__.py
+-rw-r--r--  2.0 unx     2175 b- defN 23-May-15 19:26 ts_sdk/task/__util_adapters/communication_format.py
+-rw-r--r--  2.0 unx      656 b- defN 23-May-15 19:26 ts_sdk/task/__util_adapters/curry_format.py
+-rw-r--r--  2.0 unx     1193 b- defN 23-May-15 19:26 ts_sdk/task/__util_adapters/endpoint_adapter.py
+-rw-r--r--  2.0 unx     2892 b- defN 23-May-15 19:26 ts_sdk/task/__util_adapters/make_adapter.py
+-rw-r--r--  2.0 unx     4657 b- defN 23-May-15 19:26 ts_sdk/task/__util_task/__init__.py
+-rw-r--r--  2.0 unx      108 b- defN 23-May-15 19:26 ts_sdk/task/__util_task/exceptions.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-15 19:26 ts_sdk/task/log_codes/__init__.py
+-rw-r--r--  2.0 unx      178 b- defN 23-May-15 19:26 ts_sdk/task/log_codes/log_code.py
+-rw-r--r--  2.0 unx     1831 b- defN 23-May-15 19:26 ts_sdk/task/log_codes/log_code_collection.py
+-rw-r--r--  2.0 unx     4348 b- defN 23-May-15 19:26 ts_sdk/task/log_codes/log_code_collection_meta.py
+-rw-r--r--  2.0 unx     1967 b- defN 23-May-15 19:26 ts_sdk/task/log_codes/log_code_validator.py
+-rw-r--r--  2.0 unx      106 b- defN 23-May-15 19:26 ts_sdk/taskdev/__init__.py
+-rw-r--r--  2.0 unx     5255 b- defN 23-May-15 19:26 ts_sdk/taskdev/context.py
+-rw-r--r--  2.0 unx     1502 b- defN 23-May-15 19:26 ts_sdk/taskdev/testing.py
+-rw-r--r--  2.0 unx    11370 b- defN 23-May-15 19:26 ts_sdk-2.0.0rc5.dist-info/LICENSE.txt
+-rw-r--r--  2.0 unx     8699 b- defN 23-May-15 19:26 ts_sdk-2.0.0rc5.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-15 19:26 ts_sdk-2.0.0rc5.dist-info/WHEEL
+-rw-r--r--  2.0 unx       52 b- defN 23-May-15 19:26 ts_sdk-2.0.0rc5.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       17 b- defN 23-May-15 19:26 ts_sdk-2.0.0rc5.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     8507 b- defN 23-May-15 19:26 ts_sdk-2.0.0rc5.dist-info/RECORD
+92 files, 300634 bytes uncompressed, 79136 bytes compressed:  73.7%
```

## zipnote {}

```diff
@@ -252,26 +252,26 @@
 
 Filename: ts_sdk/taskdev/context.py
 Comment: 
 
 Filename: ts_sdk/taskdev/testing.py
 Comment: 
 
-Filename: ts_sdk-2.0.0rc4.dist-info/LICENSE.txt
+Filename: ts_sdk-2.0.0rc5.dist-info/LICENSE.txt
 Comment: 
 
-Filename: ts_sdk-2.0.0rc4.dist-info/METADATA
+Filename: ts_sdk-2.0.0rc5.dist-info/METADATA
 Comment: 
 
-Filename: ts_sdk-2.0.0rc4.dist-info/WHEEL
+Filename: ts_sdk-2.0.0rc5.dist-info/WHEEL
 Comment: 
 
-Filename: ts_sdk-2.0.0rc4.dist-info/entry_points.txt
+Filename: ts_sdk-2.0.0rc5.dist-info/entry_points.txt
 Comment: 
 
-Filename: ts_sdk-2.0.0rc4.dist-info/top_level.txt
+Filename: ts_sdk-2.0.0rc5.dist-info/top_level.txt
 Comment: 
 
-Filename: ts_sdk-2.0.0rc4.dist-info/RECORD
+Filename: ts_sdk-2.0.0rc5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## __tests__/unit/test_allowed_ids.py

```diff
@@ -20,15 +20,17 @@
     # Arrange
     ids = {"namespace": "common", "slug": "example", "version": "v1.0.0"}
     allowed_ids_str = "common/example:v1.0.0"
     non_allowed_ids_str = "common/non-allowed-ids:v1.0.0"
     allowed_ids = AllowedIDS.from_allowedIds(ids)
 
     # Act and Assert
-    assert isinstance(allowed_ids.allowed_ids, IDS)
+    assert isinstance(allowed_ids.allowed_ids, list)
+    assert len(allowed_ids.allowed_ids) == 1
+    assert isinstance(allowed_ids.allowed_ids[0], IDS)
     assert (
         allowed_ids.get_ids_to_be_written("common/example:v1.0.0")
         == "common/example:v1.0.0"
     )
     assert allowed_ids.get_ids_to_be_written(None) == "common/example:v1.0.0"
 
     with pytest.raises(IDSNotAllowed):
```

## __tests__/unit/test_cli_put.py

```diff
@@ -1,30 +1,76 @@
 import argparse
 import io
 import os
 
+import json
 import pytest
 
 from ts_sdk.cli.__put_cmd import __ensure_args, __namespace_type
 
 
-def test_ensure_args():
-    os.environ.update({"TS_ORG": "env-org", "TS_API_URL": "env-api-url"})
-    args = argparse.Namespace(
-        org="arg-org",
-        ignore_ssl=False,
-        config=io.StringIO(
-            '{"org": "cfg-org", "auth_token": "cfg-token", "ignore_ssl": true}'
+@pytest.mark.parametrize(
+    "args,cfg,envs,expected",
+    [
+        (
+            {"org": "arg-org", "api_url": "arg-api-url", "ignore_ssl": False},
+            {
+                "org": "cfg-org",
+                "auth_token": "cfg-token",
+                "ignore_ssl": True,
+                "api_url": "cfg-api-url",
+            },
+            {"TS_ORG": "env-org", "TS_API_URL": "env-api-url"},
+            {
+                "org": "arg-org",
+                "api_url": "arg-api-url",
+                "auth_token": "cfg-token",
+                "ignore_ssl": True,
+            },
+        ),
+        (
+            {"org": "arg-org", "ignore_ssl": False},
+            None,
+            {"TS_ORG": "env-org", "TS_API_URL": "env-api-url"},
+            {
+                "org": "arg-org",
+                "api_url": "env-api-url",
+                "auth_token": None,
+                "ignore_ssl": False,
+            },
+        ),
+        (
+            {},
+            {
+                "org": "cfg-org",
+                "auth_token": "cfg-token",
+                "ignore_ssl": True,
+                "api_url": "cfg-api-url",
+            },
+            {"TS_ORG": "env-org", "TS_API_URL": "env-api-url"},
+            {
+                "org": "cfg-org",
+                "api_url": "cfg-api-url",
+                "auth_token": "cfg-token",
+                "ignore_ssl": True,
+            },
         ),
-    )
-    __ensure_args(args)
-    assert args.api_url == "env-api-url"
-    assert args.org == "arg-org"
-    assert args.auth_token == "cfg-token"
-    assert args.ignore_ssl == True
+    ],
+)
+def test_ensure_args(args, cfg, envs, expected):
+    os.environ.clear()
+    os.environ.update(envs)
+    if cfg:
+        args["config"] = io.StringIO(json.dumps(cfg))
+    parsed_args = argparse.Namespace(**args)
+    __ensure_args(parsed_args)
+    assert getattr(parsed_args, "api_url", None) == expected["api_url"]
+    assert getattr(parsed_args, "org", None) == expected["org"]
+    assert getattr(parsed_args, "auth_token", None) == expected["auth_token"]
+    assert getattr(parsed_args, "ignore_ssl", None) == expected["ignore_ssl"]
 
 
 @pytest.mark.parametrize(
     "namespace",
     [
         # valid namespaces
         "private-123",
```

## __tests__/unit/test_context.py

```diff
@@ -1,21 +1,22 @@
 import os
-from argparse import Namespace
+import typing as t
 from unittest import TestCase
 from unittest.mock import MagicMock, patch
 
 import pytest
 
 from ts_sdk.task.__task_script_runner import Context
 from ts_sdk.task.__util_config import (
     IDS,
     MISSING_ALLOWED_IDS,
     AllowedIDS,
     IDSInvalidWrite,
     IDSNotAllowed,
+    IDSValidateWrongParams,
 )
 
 
 class LogMock:
     def log(self, data):
         print(data)
 
@@ -43,15 +44,19 @@
 
         self.pipeline_config = {"ts_secret_name_password": "some/kms/path"}
         self.allowed_ids = AllowedIDS.from_allowedIds(
             {"namespace": "common", "slug": "example", "version": "v1.0.0"}
         )
 
         self.context_to_test = Context(
-            {"inputFile": self.input_file, "pipelineConfig": self.pipeline_config},
+            {
+                "inputFile": self.input_file,
+                "pipelineConfig": self.pipeline_config,
+                "orgSlug": "org_slug_from_context",
+            },
             self.datalake_mock,
             self.ids_mock,
             MagicMock(),  # logger
             self.allowed_ids,
         )
 
     def tearDown(self):
@@ -90,15 +95,19 @@
         self.context_to_test.write_file("content", "file_name", "RAW")
 
         # Assert
         self.datalake_mock.write_file.assert_called_once_with(
             content="content",
             context=self.context_to_test._obj,
             file_category="RAW",
-            file_meta={"ts_integration_metadata": "", "ts_integration_tags": ""},
+            file_meta={
+                "ts_integration_metadata": "",
+                "ts_integration_tags": "",
+                "ts_trace_id": "11111111-eeee-4444-bbbb-222222222222",
+            },
             file_name="file_name",
             ids=None,
             labels=(),
             raw_file=self.input_file,
             source_type=None,
             gzip_compress_level=5,
         )
@@ -122,15 +131,19 @@
         self.context_to_test.write_file("content", "file_name", "IDS", ids=None)
 
         # Assert
         self.datalake_mock.write_file.assert_called_once_with(
             content="content",
             context=self.context_to_test._obj,
             file_category="IDS",
-            file_meta={"ts_integration_metadata": "", "ts_integration_tags": ""},
+            file_meta={
+                "ts_integration_metadata": "",
+                "ts_integration_tags": "",
+                "ts_trace_id": "11111111-eeee-4444-bbbb-222222222222",
+            },
             file_name="file_name",
             ids=None,
             labels=(),
             raw_file=self.input_file,
             source_type=None,
             gzip_compress_level=5,
         )
@@ -152,15 +165,19 @@
         )
 
         # Assert
         self.datalake_mock.write_file.assert_called_once_with(
             content="content",
             context=self.context_to_test._obj,
             file_category="IDS",
-            file_meta={"ts_integration_metadata": "", "ts_integration_tags": ""},
+            file_meta={
+                "ts_integration_metadata": "",
+                "ts_integration_tags": "",
+                "ts_trace_id": "11111111-eeee-4444-bbbb-222222222222",
+            },
             file_name="file_name",
             ids="common/my-ids:v1.0.0",
             labels=(),
             raw_file=self.input_file,
             source_type=None,
             gzip_compress_level=5,
         )
@@ -225,15 +242,19 @@
         self.context_to_test.write_file("content", "file_name", "IDS", ids=None)
 
         # Assert
         self.datalake_mock.write_file.assert_called_once_with(
             content="content",
             context=self.context_to_test._obj,
             file_category="IDS",
-            file_meta={"ts_integration_metadata": "", "ts_integration_tags": ""},
+            file_meta={
+                "ts_integration_metadata": "",
+                "ts_integration_tags": "",
+                "ts_trace_id": "11111111-eeee-4444-bbbb-222222222222",
+            },
             file_name="file_name",
             ids="common/my-ids:v1.0.0",
             labels=(),
             raw_file=self.input_file,
             source_type=None,
             gzip_compress_level=5,
         )
@@ -254,15 +275,19 @@
         self.context_to_test.write_file("content", "file_name", "IDS", ids=None)
 
         # Assert
         self.datalake_mock.write_file.assert_called_once_with(
             content="content",
             context=self.context_to_test._obj,
             file_category="IDS",
-            file_meta={"ts_integration_metadata": "", "ts_integration_tags": ""},
+            file_meta={
+                "ts_integration_metadata": "",
+                "ts_integration_tags": "",
+                "ts_trace_id": "11111111-eeee-4444-bbbb-222222222222",
+            },
             file_name="file_name",
             ids="common/my-ids:v1.0.0",
             labels=(),
             raw_file=self.input_file,
             source_type=None,
             gzip_compress_level=5,
         )
@@ -353,14 +378,76 @@
         self.context_to_test._allowed_ids = AllowedIDS(allowed_ids)
 
         self.context_to_test.validate_ids("data", "common", "my-ids", "v1.0.0")
         self.ids_mock["validate_ids"].assert_called_once_with(
             "data", "common", "my-ids", "v1.0.0"
         )
 
+    def test_validate_ids_when_ns_slug_version_not_set(self):
+        """
+        Validate an allowed IDS. Make sure function is called with proper arguments
+        """
+        allowed_ids: IDS = IDS(namespace="common", slug="my-ids", version="v1.0.0")
+        self.context_to_test._allowed_ids = AllowedIDS(allowed_ids)
+
+        self.context_to_test.validate_ids("data")
+        self.ids_mock["validate_ids"].assert_called_once_with(
+            "data", "common", "my-ids", "v1.0.0"
+        )
+
+    def test_validate_ids_when_ns_slug_version_not_set_and_allowed_ids_is_list(self):
+        """
+        Validate an allowed IDS. Make sure function is called with proper arguments
+        """
+        allowed_ids: t.Iterable[IDS] = [
+            IDS(namespace="common", slug="my-ids", version="v1.0.0"),
+            IDS(namespace="common", slug="my-ids", version="v2.0.0"),
+        ]
+        self.context_to_test._allowed_ids = AllowedIDS(allowed_ids)
+
+        with pytest.raises(IDSValidateWrongParams):
+            self.context_to_test.validate_ids("data")
+
+    def test_validate_ids_when_ns_slug_version_not_set_and_allowed_ids_is_missing(self):
+        """
+        Validate an allowed IDS. Make sure function is called with proper arguments
+        """
+        self.context_to_test._allowed_ids = MISSING_ALLOWED_IDS
+
+        with pytest.raises(IDSValidateWrongParams):
+            self.context_to_test.validate_ids("data")
+
+    def test_validate_ids_when_one_of_param_is_not_set(self):
+        """
+        Validate an allowed IDS. Make sure function is called with proper arguments
+        """
+        allowed_ids: IDS = IDS(namespace="common", slug="my-ids", version="v1.0.0")
+        self.context_to_test._allowed_ids = AllowedIDS(allowed_ids)
+
+        with pytest.raises(IDSValidateWrongParams):
+            self.context_to_test.validate_ids("data", "common", "my-ids")
+        with pytest.raises(IDSValidateWrongParams):
+            self.context_to_test.validate_ids("data", "common")
+        with pytest.raises(IDSValidateWrongParams):
+            self.context_to_test.validate_ids("data", version="v1.0.0")
+
+    def test_validate_ids_when_ignore_allowed_ids_is_true(self):
+        """
+        Validate an allowed IDS. Make sure function is called with proper arguments
+        """
+        allowed_ids: IDS = IDS(namespace="common", slug="my-ids", version="v1.0.0")
+        self.context_to_test._allowed_ids = AllowedIDS(allowed_ids)
+
+        self.context_to_test.validate_ids(
+            "data", "common", "my-ids", "v2.0.0", ignore_allowed_ids=True
+        )
+        self.ids_mock["validate_ids"].assert_called_once_with(
+            "data", "common", "my-ids", "v2.0.0"
+        )
+
     ##############################################
 
     def test_write_ids(self):
         """Test that write_ids calls the correct methods"""
         # Act
         self.context_to_test.write_ids("content", "file_suffix")
 
@@ -384,15 +471,19 @@
         self.context_to_test.write_ids("content", "file_suffix", ids=None)
 
         # Assert
         self.datalake_mock.write_ids.assert_called_once_with(
             content_obj="content",
             context=self.context_to_test._obj,
             file_category="IDS",
-            file_meta={"ts_integration_metadata": "", "ts_integration_tags": ""},
+            file_meta={
+                "ts_integration_metadata": "",
+                "ts_integration_tags": "",
+                "ts_trace_id": "11111111-eeee-4444-bbbb-222222222222",
+            },
             ids=None,
             labels=(),
             raw_file=self.input_file,
             source_type=None,
             file_suffix="file_suffix",
             gzip_compress_level=5,
         )
@@ -414,15 +505,19 @@
         )
 
         # Assert
         self.datalake_mock.write_ids.assert_called_once_with(
             content_obj="content",
             context=self.context_to_test._obj,
             file_category="IDS",
-            file_meta={"ts_integration_metadata": "", "ts_integration_tags": ""},
+            file_meta={
+                "ts_integration_metadata": "",
+                "ts_integration_tags": "",
+                "ts_trace_id": "11111111-eeee-4444-bbbb-222222222222",
+            },
             ids="common/my-ids:v1.0.0",
             labels=(),
             raw_file=self.input_file,
             source_type=None,
             file_suffix="file_suffix",
             gzip_compress_level=5,
         )
@@ -487,15 +582,19 @@
         self.context_to_test.write_ids("content", "file_suffix", ids=None)
 
         # Assert
         self.datalake_mock.write_ids.assert_called_once_with(
             content_obj="content",
             context=self.context_to_test._obj,
             file_category="IDS",
-            file_meta={"ts_integration_metadata": "", "ts_integration_tags": ""},
+            file_meta={
+                "ts_integration_metadata": "",
+                "ts_integration_tags": "",
+                "ts_trace_id": "11111111-eeee-4444-bbbb-222222222222",
+            },
             ids="common/my-ids:v1.0.0",
             labels=(),
             raw_file=self.input_file,
             source_type=None,
             file_suffix="file_suffix",
             gzip_compress_level=5,
         )
@@ -516,15 +615,19 @@
         self.context_to_test.write_ids("content", "file_suffix", ids=None)
 
         # Assert
         self.datalake_mock.write_ids.assert_called_once_with(
             content_obj="content",
             context=self.context_to_test._obj,
             file_category="IDS",
-            file_meta={"ts_integration_metadata": "", "ts_integration_tags": ""},
+            file_meta={
+                "ts_integration_metadata": "",
+                "ts_integration_tags": "",
+                "ts_trace_id": "11111111-eeee-4444-bbbb-222222222222",
+            },
             ids="common/my-ids:v1.0.0",
             labels=(),
             raw_file=self.input_file,
             source_type=None,
             file_suffix="file_suffix",
             gzip_compress_level=5,
         )
@@ -606,15 +709,39 @@
     def test_run_command(self, run_command_mock):
         """Tests that the run_command method calls the correct methods"""
         # Act
         self.context_to_test.run_command(
             "org_slug", "target_id", "action", {"meta1": "v1"}, "payload"
         )
         # Assert
-        run_command_mock.assert_called_once()
+        run_command_mock.assert_called_once_with(
+            self.context_to_test._obj,
+            "org_slug",
+            "target_id",
+            "action",
+            {"meta1": "v1"},
+            "payload",
+            300,
+        )
+
+    @patch("ts_sdk.task.__task_script_runner.run_command")
+    def test_run_cmd(self, run_command_mock):
+        """Tests that the run_cmd method calls the correct methods"""
+        # Act
+        self.context_to_test.run_cmd("target_id", "action", {"meta1": "v1"}, "payload")
+        # Assert
+        run_command_mock.assert_called_once_with(
+            self.context_to_test._obj,
+            "org_slug_from_context",
+            "target_id",
+            "action",
+            {"meta1": "v1"},
+            "payload",
+            300,
+        )
 
     @patch("ts_sdk.task.__task_script_runner.add_labels")
     @patch("ts_sdk.task.__task_script_runner.validate_file_labels")
     def test_add_labels(self, validate_file_labels_mock, add_labels_mock):
         """Test that add_labels calls the correct function and correctly validates"""
         # Act
         self.context_to_test.add_labels(
@@ -642,14 +769,28 @@
         self.context_to_test.delete_labels(self.input_file, [1, 2, 3])
 
         # Arrange
         delete_labels_mock.assert_called_once_with(
             self.context_to_test._obj, self.input_file["fileId"], [1, 2, 3]
         )
 
+    @patch("ts_sdk.task.__task_script_runner.delete_labels")
+    def test_delete_none_labels(self, delete_labels_mock):
+        """
+        Test that delete_labels calls the correct method and replaced None with an
+        empty list
+        """
+        # Act
+        self.context_to_test.delete_labels(self.input_file, None)
+
+        # Arrange
+        delete_labels_mock.assert_called_once_with(
+            self.context_to_test._obj, self.input_file["fileId"], []
+        )
+
     @patch("ts_sdk.task.__task_script_runner.add_labels")
     @patch("ts_sdk.task.__task_script_runner.validate_file_labels")
     def test_add_attributes_labels_only(
         self, validate_file_labels_mock, add_labels_mock
     ):
         """Test that add_attributes calls the correct methods when only tags are supplied"""
```

## __tests__/unit/test_fileinfo.py

```diff
@@ -33,27 +33,31 @@
 
 add_label_args = [
     dummy_context_data,
     file_id,
     [{"name": "label1", "value": "label-value-1"}],
 ]
 get_label_args = [dummy_context_data, file_id]
+delete_label_empty_args = [dummy_context_data, file_id, []]
 delete_label_args = [dummy_context_data, file_id, ["label_id"]]
 
 
 def test_format_unsupported():
     os.environ.update({COMMUNICATION_FORMAT_ENV_KEY: "unknown"})
 
     with pytest.raises(NotImplementedError):
         add_labels(*add_label_args)
 
     with pytest.raises(NotImplementedError):
         get_labels(*get_label_args)
 
     with pytest.raises(NotImplementedError):
+        delete_labels(*delete_label_empty_args)
+
+    with pytest.raises(NotImplementedError):
         delete_labels(*delete_label_args)
 
 
 def __test_file_info_adapter(
     request_mock,
     endpoint,
     endpoint_env_key,
@@ -133,14 +137,38 @@
         f"/api/v1/fileinfo/files/{file_id}/labels",
         CommunicationFormat.V1,
         lambda: get_labels(*get_label_args),
     )
 
 
 @patch("requests.delete")
+def test_delete_empty_labels_v0(delete_mocker):
+    return __test_file_info_adapter(
+        delete_mocker,
+        "http://fileinfo.local",
+        "FILEINFO_ENDPOINT",
+        f"/internal/{org_slug}/files/{file_id}/labels",
+        CommunicationFormat.V0,
+        lambda: delete_labels(*delete_label_empty_args),
+    )
+
+
+@patch("requests.delete")
+def test_delete_empty_labels_v1(delete_mocker):
+    return __test_file_info_adapter(
+        delete_mocker,
+        "https://localhost:443",
+        "KERNEL_ENDPOINT",
+        f"/api/v1/fileinfo/files/{file_id}/labels",
+        CommunicationFormat.V1,
+        lambda: delete_labels(*delete_label_empty_args),
+    )
+
+
+@patch("requests.delete")
 def test_delete_labels_v0(delete_mocker):
     return __test_file_info_adapter(
         delete_mocker,
         "http://fileinfo.local",
         "FILEINFO_ENDPOINT",
         f"/internal/{org_slug}/files/{file_id}/labels",
         CommunicationFormat.V0,
```

## __tests__/unit/test_util_validation.py

```diff
@@ -1,8 +1,8 @@
-from typing import Any, List, Union
+from typing import Any
 
 import pytest
 
 from ts_sdk.task.__util_validation import (
     validate_file_labels,
     validate_file_meta,
     validate_file_tags,
@@ -175,45 +175,59 @@
     with pytest.raises(ValueError):
         validate_file_labels(invalid_label_input)
 
 
 @pytest.mark.parametrize(
     "valid_label_input",
     [
-        [],
         [
             {"name": "boring", "value": "boring"},
         ],
         [
             {"name": "boring", "value": "boring"},
             {"name": "boring2", "value": "boring2"},
         ],
         [{"name": str(x), "value": str(x)} for x in range(25)],
         [
             {"name": "same_name", "value": "a_value"},
             {"name": "same_name", "value": "different_value"},
         ],
-        map(lambda x: {"name": str(x), "value": str(x)}, range(10)),  # unusual iterable
+        ({"name": "same_name", "value": "a_value"},),
+        (
+            {"name": "same_name", "value": "a_value"},
+            {"name": "same_name", "value": "different_value"},
+        ),
     ],
     ids=[
-        "empty list",
         "single item",
         "two items",
         "many items",
         "two items with the same name",
-        "unusual iterable",
+        "single item tuple",
+        "multiple items in tuple",
     ],
 )
 def test_valid_label_inputs(valid_label_input: Any) -> None:
     """Test that invalid inputs trigger errors"""
     # Arrange and Act
-    is_valid = validate_file_labels(valid_label_input)
+    assert validate_file_labels(valid_label_input)
 
-    # Assert
-    assert is_valid
+
+@pytest.mark.parametrize(
+    "empty_label_input",
+    [
+        None,
+        [],
+        (),
+    ],
+    ids=["none", "empty list", "empty tuple"],
+)
+def test_empty_list_label_input(empty_label_input: Any) -> None:
+    """Test that validation functions differ in behaviour on the empty list"""
+    assert validate_file_labels(empty_label_input) == False
 
 
 NAME_MAX_LENGTH = 128
 VALUE_MAX_LENGTH = 256
 DELTA = 10
 
 
@@ -225,18 +239,15 @@
 def test_name_length(num_characters) -> None:
     """Test that key length is limited correctly"""
     # Arrange
     long_string = "x" * num_characters
     labels = [{"name": long_string, "value": "_"}]
 
     # Act
-    is_valid = validate_file_labels(labels)
-
-    # Assert
-    assert is_valid
+    assert validate_file_labels(labels)
 
 
 @pytest.mark.parametrize(
     "num_characters",
     range(NAME_MAX_LENGTH + 1, NAME_MAX_LENGTH + DELTA + 2),
     ids=lambda num: f"name cannot have {num} characters",
 )
@@ -259,18 +270,15 @@
 def test_value_length(num_characters) -> None:
     """Test that key length is limited correctly"""
     # Arrange
     long_string = "x" * num_characters
     labels = [{"name": "_", "value": long_string}]
 
     # Act
-    is_valid = validate_file_labels(labels)
-
-    # Assert
-    assert is_valid
+    assert validate_file_labels(labels)
 
 
 @pytest.mark.parametrize(
     "num_characters",
     range(VALUE_MAX_LENGTH + 1, VALUE_MAX_LENGTH + DELTA + 2),
     ids=lambda num: f"value cannot have {num} characters",
 )
@@ -287,10 +295,8 @@
 
 def test_validation_with_dataclass_labels():
     """Test that we can use the label dataclass in our validation functions"""
     # Arrange
     labels = [Label("name", "value"), Label(value="value2", name="name2")]
 
     # Act
-    is_valid = validate_file_labels(labels)
-
-    assert is_valid
+    assert validate_file_labels(labels)
```

## ts_sdk/cli/__put_cmd.py

```diff
@@ -126,28 +126,28 @@
             f"hyphens."
         )
 
     return arg_value
 
 
 def __ensure_args(args: argparse.Namespace):
-    # from env
-    env_prefix = "TS_"
-    for k, v in os.environ.items():
-        if k.startswith(env_prefix):
-            arg_key = k.replace(env_prefix, "").lower()
-            if getattr(args, arg_key, None) in [None, False]:
-                setattr(args, arg_key, v)
-
     # from config
-    if args.config:
+    if getattr(args, "config", None):
         parsed_config = json.load(args.config)
         for k, v in parsed_config.items():
             if getattr(args, k, None) in [None, False]:
                 setattr(args, k, v)
+    else:
+        # from env
+        env_prefix = "TS_"
+        for k, v in os.environ.items():
+            if k.startswith(env_prefix):
+                arg_key = k.replace(env_prefix, "").lower()
+                if getattr(args, arg_key, None) in [None, False]:
+                    setattr(args, arg_key, v)
 
     args.ignore_ssl = args.ignore_ssl in [True, "true", "True", "1"]
 
 
 def __validate_ids(args):
     print("\n* Validating IDS")
     ids_is_valid = validate_ids(Path(args.folder), None)
```

## ts_sdk/task/__task_script_runner.py

```diff
@@ -1,29 +1,28 @@
 import importlib
 import json
 import os
 import re
 import typing as t
 import uuid
 
+from ts_sdk.task.__util_fileinfo import add_labels, delete_labels, get_labels
+
 from .__util_command import run_command
 from .__util_config import (
     MISSING_ALLOWED_IDS,
     AllowedIDS,
     FunctionConfig,
+    IDSValidateWrongParams,
     MissingAllowedIDS,
     NoAllowedIdsSpecified,
 )
 from .__util_datalake import Datalake
+from .__util_decorators import deprecated
 from .__util_es_datalake import es_datalake_search_eql, es_hit_to_file_pointer
-from ts_sdk.task.__util_fileinfo import (
-    add_labels,
-    get_labels,
-    delete_labels,
-)
 from .__util_ids import create_ids_util
 from .__util_log import Log
 from .__util_merge import merge_arrays, merge_objects
 from .__util_metadata import FIELDS
 from .__util_storage import Storage
 from .__util_validation import (
     validate_file_labels,
@@ -96,34 +95,34 @@
     task_created_at: str
 
     pipeline_config: t.Mapping[str, str]
 
     platform_url: str
     platform_version: str
 
-    tmp_dir: str = "/tmp"
+    tmp_dir: str
 
     def __init__(
         self,
         obj,
         datalake,
         ids_util,
         log,
         allowed_ids: t.Union[AllowedIDS, MissingAllowedIDS] = MISSING_ALLOWED_IDS,
     ):
         self._obj = {
             **obj,
-            "tmpDir": "/tmp",
         }  # keys are later converted to snake case via "camel_to_snake"
         for key in self._obj:
             setattr(self, camel_to_snake(key), self._obj[key])
         self._datalake = datalake
         self._ids_util = ids_util
         self._log = log
         self._allowed_ids = allowed_ids
+        self.tmp_dir = os.environ.get("TMPDIR")
 
     @property
     def allowed_ids(self) -> AllowedIDS:
         """Returns AllowedIDS object that either stores the list of allowed ids or
         a dict of allowed ids in `allowed_ids` attribute. These values are populated
         from `config.json`
 
@@ -178,15 +177,15 @@
                 {"size": 1, "query": {"term": {"fileId": {"value": file["fileId"]}}}},
                 returns="filePointers",
             )
             if len(es_files) == 0:
                 raise Exception(f"File with fileId {file['fileId']} not found!")
             file = es_files[0]
 
-        return self._datalake.read_file(file, form)
+        return self._datalake.read_file(file, form, self.tmp_dir)
 
     @wrap_log("context.write_file")
     def write_file(
         self,
         content: t.Union[bytes, t.BinaryIO, str, t.Dict],
         file_name: str,
         file_category: FileCategory,
@@ -245,14 +244,17 @@
         file_meta[FIELDS["CUSTOM_METADATA"]] = merge_objects(
             file_meta.get(FIELDS["CUSTOM_METADATA"], ""), custom_metadata
         )
         file_meta[FIELDS["CUSTOM_TAGS"]] = merge_arrays(
             file_meta.get(FIELDS["CUSTOM_TAGS"], ""),
             custom_tags,
         )
+        file_meta[FIELDS["TRACE_ID"]] = file_meta.get(
+            FIELDS["TRACE_ID"], raw_file["fileId"]
+        )
         return self._datalake.write_file(
             context=self._obj,
             content=content,
             file_name=file_name,
             file_category=file_category,
             raw_file=raw_file,
             file_meta=file_meta,
@@ -264,22 +266,50 @@
 
     @wrap_log("context.get_ids")
     def get_ids(self, namespace: str, slug: str, version: str):
         """Returns IDS schema"""
         return self._ids_util["get_ids"](namespace, slug, version)
 
     @wrap_log("context.validate_ids")
-    def validate_ids(self, data, namespace: str, slug: str, version: str):
+    def validate_ids(
+        self,
+        data: t.Any,
+        namespace: t.Optional[str] = None,
+        slug: t.Optional[str] = None,
+        version: t.Optional[str] = None,
+        ignore_allowed_ids: bool = False,
+    ):
         """
-        1. Check if IDS is present in 'allowedIds', when `allowedIds` is defined in `config.json`.
-        2. Checks validity of IDS content provided in `data`.
-        Throws an error if not valid.
+        1. Determine IDS from allowedIds when namespace, slug and versions are None
+        2. Check if IDS is present in 'allowedIds', when `allowedIds` is defined in `config.json`.
+        3. Checks validity of IDS content provided in `data`.
+        Throws an error if not valid or not possible to determine IDS from allowedIds
         """
 
-        if self._allowed_ids != MISSING_ALLOWED_IDS:
+        if namespace and slug and version:
+            pass
+        elif namespace or slug or version:
+            raise IDSValidateWrongParams(
+                f"Namespace, slug and version have to be set or equal to None: {namespace}/{slug}:{version}"
+            )
+        else:
+            # all namespace, slug and version are None
+            if self._allowed_ids == MISSING_ALLOWED_IDS:
+                raise IDSValidateWrongParams(
+                    f"Not possible to determine the IDS to validate against: allowedIds is missing"
+                )
+
+            if self._allowed_ids.is_single():
+                namespace, slug, version = self._allowed_ids.get_first().to_tuple()
+            else:
+                raise IDSValidateWrongParams(
+                    f"Not possible to determine the IDS to validate against: allowedIds has more than 1 value"
+                )
+
+        if not ignore_allowed_ids and self._allowed_ids != MISSING_ALLOWED_IDS:
             ids_str = f"{namespace}/{slug}:{version}"
             self.allowed_ids.is_reconcilable(ids_str)
 
         return self._ids_util["validate_ids"](data, namespace, slug, version)
 
     @wrap_log("context.write_ids")
     def write_ids(
@@ -344,14 +374,17 @@
         file_meta[FIELDS["CUSTOM_METADATA"]] = merge_objects(
             file_meta.get(FIELDS["CUSTOM_METADATA"], ""), custom_metadata
         )
         file_meta[FIELDS["CUSTOM_TAGS"]] = merge_arrays(
             file_meta.get(FIELDS["CUSTOM_TAGS"], ""),
             custom_tags,
         )
+        file_meta[FIELDS["TRACE_ID"]] = file_meta.get(
+            FIELDS["TRACE_ID"], raw_file["fileId"]
+        )
 
         return self._datalake.write_ids(
             context=self._obj,
             content_obj=content_obj,
             file_suffix=file_suffix,
             raw_file=raw_file,
             file_meta=file_meta,
@@ -425,48 +458,64 @@
             context=self._obj,
             file=file,
             custom_meta=custom_meta,
             custom_tags=custom_tags,
             options=options,
         )
 
+    @deprecated("'context.run_command' deprecated, use 'context.run_cmd' instead!")
     @wrap_log("context.run_command")
     def run_command(self, org_slug, target_id, action, metadata, payload, ttl_sec=300):
         """Invokes remote command/action on target (agent or connector) and returns its response"""
         return run_command(
             self._obj, org_slug, target_id, action, metadata, payload, ttl_sec
         )
 
+    @wrap_log("context.run_cmd")
+    def run_cmd(self, target_id, action, metadata, payload, ttl_sec=300):
+        """Invokes remote command/action on target (agent or connector) and returns its response"""
+        return run_command(
+            self._obj, self.org_slug, target_id, action, metadata, payload, ttl_sec
+        )
+
     def get_file_id(self, file):
         if "fileId" in file:
             file_id = file["fileId"]
         else:
             file_metadata = self._datalake.get_file_meta(file)
             file_id = file_metadata.get(FIELDS["FILE_ID"])
         return file_id
 
     @wrap_log("context.add_labels")
     def add_labels(
         self,
         file: File,
-        labels: t.Collection[AnyLabel],
+        labels: t.Optional[t.Collection[AnyLabel]],
         no_propagate: bool = False,
     ):
-        validate_file_labels(labels)
-        file_id = self.get_file_id(file)
-        return add_labels(self._obj, file_id, labels, no_propagate)
+        if validate_file_labels(labels):
+            file_id = self.get_file_id(file)
+            return add_labels(self._obj, file_id, labels, no_propagate)
+        else:
+            print(
+                {
+                    "level": "warning",
+                    "message": "no labels provided in add_labels()!",
+                }
+            )
+            return self.get_labels(file)
 
     def get_labels(self, file):
         file_id = self.get_file_id(file)
         return get_labels(self._obj, file_id)
 
     @wrap_log("context.delete_labels")
     def delete_labels(self, file, label_ids):
         file_id = self.get_file_id(file)
-        return delete_labels(self._obj, file_id, label_ids)
+        return delete_labels(self._obj, file_id, label_ids if label_ids else [])
 
     @wrap_log("context.add_attributes")
     def add_attributes(
         self,
         file: File,
         custom_meta: t.Optional[t.Mapping[str, str]] = None,
         custom_tags: t.Iterable[str] = (),
@@ -479,26 +528,25 @@
         if not custom_meta and not custom_tags:
             if labels:
                 # no need to validate labels before here, because add_labels will validate for us
                 self.add_labels(file, labels)
             else:
                 print(
                     {
-                        "level": "error",
+                        "level": "warning",
                         "message": "no attributes provided in add_attributes()!",
                     }
                 )
             return file
 
         # case where meta and/or tags are specified
 
         new_file_id = str(uuid.uuid4())
 
-        if labels:
-            validate_file_labels(labels)
+        if validate_file_labels(labels):
             self._datalake.create_labels_file(
                 target_file={**file, "fileId": new_file_id},
                 # TODO: this line will overwrite the label, instead, should merge with the existing labels
                 # otherwise, the behavior is different from when metadata, tag are not provided.
                 labels=labels,
             )
```

## ts_sdk/task/__util_config.py

```diff
@@ -1,11 +1,11 @@
 import json
 import pathlib
 import re
-from typing import Iterable, List, Optional, Type, Union
+import typing as t
 
 
 class MissingAllowedIDS:
     pass
 
 
 MISSING_ALLOWED_IDS = MissingAllowedIDS()
@@ -15,14 +15,18 @@
     pass
 
 
 class IDSInvalidWrite(Exception):
     pass
 
 
+class IDSValidateWrongParams(Exception):
+    pass
+
+
 class NoAllowedIdsSpecified(Exception):
     pass
 
 
 class InvalidIDSString(ValueError):
     pass
 
@@ -47,14 +51,17 @@
             raise InvalidIDSString(
                 f"Received invalid IDS string: '{ids_str}'. IDS strings are expected to have format "
                 f"<namespace>/<slug>:<version>."
             )
         namespace, slug, version = match_result.groups()
         return IDS(namespace=namespace, slug=slug, version=version)
 
+    def to_tuple(self):
+        return self.namespace, self.slug, self.version
+
     def __str__(self):
         return f"{self.namespace}/{self.slug}:{self.version}"
 
     def __repr__(self):
         return (
             f"IDS(namespace={self.namespace}, slug={self.slug}, version={self.version})"
         )
@@ -71,19 +78,24 @@
         else:
             return False
 
 
 class AllowedIDS:
     """Abstraction for 'allowedIds' JSON object"""
 
-    def __init__(self, allowed_ids: Optional[Union[IDS, Iterable[IDS]]]):
-        self.allowed_ids = allowed_ids
+    allowed_ids: t.Iterable[IDS]
+
+    def __init__(self, allowed_ids: t.Optional[t.Union[IDS, t.Iterable[IDS]]]):
+        if isinstance(allowed_ids, IDS):
+            self.allowed_ids = [allowed_ids]
+        else:
+            self.allowed_ids = allowed_ids
 
     @classmethod
-    def from_allowedIds(cls, allowed_ids: Union[dict, List[dict], None]):
+    def from_allowedIds(cls, allowed_ids: t.Union[dict, t.List[dict], None]):
         """
         Read config.json to get the value of 'allowedIds'
         if 'allowedIds' is null, return None
         else return list of IDS object
         """
 
         if isinstance(allowed_ids, dict):
@@ -98,48 +110,48 @@
             raise ValueError(
                 "'allowedIds' for function config (in config.json) must be one of the following: \n"
                 "1. JSON object representing IDS\n"
                 "2. List of JSON objects, each representing IDS\n"
                 "3. null\n"
             )
 
-    def is_reconcilable(self, ids_requested_to_be_written: Optional[str]) -> bool:
+    def is_single(self):
+        return len(self.allowed_ids) == 1
+
+    def get_first(self):
+        return self.allowed_ids[0]
+
+    def is_reconcilable(self, ids_requested_to_be_written: t.Optional[str]) -> bool:
         if not self.allowed_ids:
             raise IDSInvalidWrite(
                 "Task Script is not allowed to write or validate IDS.\n"
                 "Please make sure 'allowedIds' for function config (in config.json) is one of the following: \n"
                 "1. JSON object representing IDS\n"
                 "2. List of JSON objects, each representing IDS\n"
             )
 
-        list_of_allowed_ids = (
-            [self.allowed_ids]
-            if isinstance(self.allowed_ids, IDS)
-            else self.allowed_ids
-        )
-
         if ids_requested_to_be_written:
             ids_obj = IDS.from_str(ids_requested_to_be_written)
-            if ids_obj not in list_of_allowed_ids:
+            if ids_obj not in self.allowed_ids:
                 raise IDSNotAllowed(
                     f"Task Script is trying to write IDS for {ids_obj}."
                     f"However, only following IDS are allowed {self.allowed_ids}"
                 )
         else:
-            if len(list_of_allowed_ids) > 1:
+            if len(self.allowed_ids) > 1:
                 raise IDSInvalidWrite(
                     f"Could not determine which IDS to use. \n"
                     f"'ids_requested_to_be_written' is set to None."
                     f"And multiple IDS are allowed : {self.allowed_ids}"
                 )
         return True
 
     def get_ids_to_be_written(
-        self, ids_requested_to_be_written: Optional[str]
-    ) -> Optional[str]:
+        self, ids_requested_to_be_written: t.Optional[str]
+    ) -> t.Optional[str]:
         """
         'ids_requested_to_be_written' is safe to use if it is present in 'allowedIds'.
         If 'ids_requested_to_be_written' is None, then safely determine which IDS should the
         task-script write.
         """
         if self.is_reconcilable(ids_requested_to_be_written):
             if not ids_requested_to_be_written:
@@ -159,15 +171,15 @@
 class FunctionConfig:
     """Abstraction for function configuration in config.json"""
 
     def __init__(self, config_dict: dict = {}):
         self._config_dict = config_dict
         self.allowed_ids = self._get_allowed_ids()
 
-    def _get_allowed_ids(self) -> Union[AllowedIDS, MissingAllowedIDS]:
+    def _get_allowed_ids(self) -> t.Union[AllowedIDS, MissingAllowedIDS]:
         if "allowedIds" not in self._config_dict:
             return MISSING_ALLOWED_IDS
         else:
             allowed_ids = self._config_dict["allowedIds"]
             return AllowedIDS.from_allowedIds(allowed_ids)
 
     @classmethod
```

## ts_sdk/task/__util_datalake.py

```diff
@@ -21,17 +21,16 @@
 from .encoders import DataclassEncoder
 from .data_model import AnyLabel, IdsUtilDict
 
 WRITE_ALLOWED_CATEGORIES = ["IDS", "PROCESSED", "TMP"]
 DISABLE_GZIP = os.environ.get("DISABLE_GZIP")
 ENV = os.environ.get("ENV")
 AWS_REGION = os.environ.get("AWS_REGION")
-MULTIPART_SIZE = (
-    100 * 1024 * 1024
-)  # don't use multipart if file size is smaller than 100MB
+# don't use multipart if file size is smaller than 100MB
+MULTIPART_SIZE = int(os.environ.get("MULTIPART_SIZE_MB", 100)) * 2**20
 LARGE_FILE_SIZE_THRESHOLD_BYTES = (
     5 * 2**30
 )  # We have to handle files that are > 5 GB differently
 
 
 def lowerMetadataKeys(metadata: dict) -> dict:
     """Lowercases all keys in a dict"""
@@ -189,15 +188,15 @@
         return head
 
     def get_file_meta(self, file):
         """Return lowercased metadata dictionary of file argument"""
         head = self.get_s3_head(file)
         return lowerMetadataKeys(head.get("Metadata"))
 
-    def read_file(self, file, form="body"):
+    def read_file(self, file, form="body", tmp_dir="/tmp"):
         """Read file from S3"""
         bucket = file["bucket"]
         file_key = file["fileKey"]
         if "version" in file:
             kwargs = {"VersionId": file["version"]}
         else:
             kwargs = {}
@@ -234,15 +233,17 @@
                     "client": self.s3,
                 },
             )
             if response.get("ContentEncoding") == "gzip":
                 file_obj = gzip.open(file_obj)
 
             if form == "download":
-                with tempfile.NamedTemporaryFile(mode="wb", delete=False) as temp:
+                with tempfile.NamedTemporaryFile(
+                    mode="wb", delete=False, dir=tmp_dir
+                ) as temp:
                     shutil.copyfileobj(file_obj, temp)
                     result["download"] = temp.name
                 file_obj.close()
             else:
                 result["file_obj"] = file_obj
 
         return result
```

## ts_sdk/task/__util_decorators.py

```diff
@@ -1,7 +1,23 @@
+def deprecated(message):
+    def deprecated_decorator(func):
+        def deprecated_func(*args, **kwargs):
+            print(
+                {
+                    "level": "warn",
+                    "message": message,
+                }
+            )
+            return func(*args, **kwargs)
+
+        return deprecated_func
+
+    return deprecated_decorator
+
+
 def return_on_failure(errors=(Exception,), default_value=None):
     def decorator(func):
         def applicator(*args, **kwargs):
             try:
                 return func(*args, **kwargs)
             except errors:
                 return default_value
```

## ts_sdk/task/__util_fileinfo.py

```diff
@@ -110,27 +110,29 @@
 
 
 @retry_if_not_found
 def delete_labels(context_data, file_id, label_ids):
     org_slug = context_data.get("orgSlug")
 
     suffix = "&".join(map(lambda id: "id=" + str(id), label_ids))
-    url = f"{request_format_adapter().get_labels_url(org_slug, file_id)}?{suffix}"
+    url = request_format_adapter().get_labels_url(org_slug, file_id)
+    if suffix:
+        url += f"?{suffix}"
     pipeline_id = context_data.get("pipelineId")
 
     # We set x-pipeline-id and x-pipeline-history to guard against self loops and circular pipelines
     headers = {
         **request_format_adapter().get_headers(org_slug),
         **format_pipeline_history_headers(pipeline_id, context_data),
     }
     response = requests.delete(url, headers=headers, verify=False)
 
     if response.status_code == 200:
         print("Labels successfully deleted")
-        return
+        return json.loads(response.text)
     elif response.status_code == 404:
         raise FileNotFoundError()
     else:
         print("Error deleting labels: " + response.text)
         raise Exception(response.text)
```

## ts_sdk/task/__util_validation.py

```diff
@@ -1,9 +1,9 @@
 import re
-from typing import Any, Iterable, List, Optional
+from typing import Any, Collection, List, Optional
 
 from ts_sdk.task.data_model import AnyLabel, Label
 
 meta_name_reg = re.compile(r"^[0-9a-zA-Z-_+ ]+$")
 meta_value_reg = re.compile(r"^[0-9a-zA-Z-_+.,/ ]+$")
 tag_reg = re.compile(r"^[0-9a-zA-Z-_+./ ]+$")
 label_name_reg = re.compile(r"^[0-9a-zA-Z-_+. ]+$")
@@ -11,15 +11,15 @@
 string_is_trimmed_reg = re.compile(r"^[^\s](.*[^\s])?$")
 
 LABEL_NAME_MAX_CHARACTER_LIMIT = 128
 LABEL_VALUE_MAX_CHARACTER_LIMIT = 256
 TAG_MAX_CHAR_LIMIT = 128
 
 
-def validate_file_meta(meta):
+def validate_file_meta(meta) -> bool:
     if meta is None:
         return True
     for key, value in meta.items():
         if not meta_name_reg.match(key):
             raise ValueError(
                 f"Invalid metadata key {key}! Expected pattern: {meta_name_reg.pattern}"
             )
@@ -28,15 +28,15 @@
                 f"Invalid metadata value {value}! Expected pattern: {meta_value_reg.pattern}"
             )
         validate_string_is_trimmed(key)
         validate_string_is_trimmed(value)
     return True
 
 
-def validate_file_tags(tags: List[str]):
+def validate_file_tags(tags: List[str]) -> bool:
     """
     Validate file tags as per https://developers.tetrascience.com/docs/basic-concepts-metadata-tags-and-labels
     """
     if tags is None:
         return True
     for tag in tags:
         if not isinstance(tag, str):
@@ -46,102 +46,120 @@
         if len(tag) > TAG_MAX_CHAR_LIMIT:
             raise ValueError(f"Tag length is greater that 128 chars. tag: {tag}")
         if not tag_reg.match(str(tag)):
             raise ValueError(f"Invalid tag {tag}! Expected pattern: {tag_reg.pattern}")
     return True
 
 
-def validate_file_labels(labels: Optional[Iterable[AnyLabel]]) -> bool:
+def cast_iterable(maybe_iterable, identifier) -> Collection:
+    try:
+        return iter(maybe_iterable)
+    except TypeError:
+        raise ValueError(
+            f"{identifier} must be an iterable.  Given {type(maybe_iterable)}."
+        )
+
+
+def validate_not_none(maybe_none, identifier) -> bool:
+    if maybe_none is None:
+        raise ValueError(f"{identifier} should not be None.  Given None.")
+    return True
+
+
+def validate_not_empty(maybe_empty, identifier) -> bool:
+    collection = cast_iterable(maybe_empty, identifier)
+    if len(collection) == 0:
+        raise ValueError(
+            f"{identifier} must be a non-empty iterable of labels. Given an empty iterable."
+        )
+    return True
+
+
+def validate_file_labels(labels: Optional[Collection[AnyLabel]]) -> bool:
     """
     Validates the list of labels given.
-
     List of labels must be made up of Label dictionaries
     """
-    if labels is None:
-        return True
+    if labels is None or len(labels) == 0:
+        return False
 
     # make sure the input is iterable
-    try:
-        iterable = iter(labels)
-    except TypeError:
-        raise ValueError(
-            f"Labels must be an iterable of Label dictionaries.  Given {type(labels)}."
-        )
-
-    valid_keys = {"name", "value"}
-    errors = []
-    for label in iterable:
-        if not isinstance(label, (dict, Label)):
-            errors.append(
-                f'Label must be a dictionary of the form {{"name": "foo", "value": "bar"}} or an instance of "ts_sdk.task.types.Label". Given: {label} ({type(label)})'
-            )
-            continue
-        if isinstance(label, dict):
-            # validate the shape of the dictionary
-            label_keys = set(label.keys())
-            if valid_keys - label_keys:
+    labels_iter = cast_iterable(labels, "Labels")
+    if labels_iter:
+        valid_keys = {"name", "value"}
+        errors = []
+        for label in labels_iter:
+            if not isinstance(label, (dict, Label)):
                 errors.append(
-                    f"Label is missing required keys: {list(valid_keys - label_keys)}. Given: {label}"
+                    f'Label must be a dictionary of the form {{"name": "foo", "value": "bar"}} or an instance of "ts_sdk.task.types.Label". Given: {label} ({type(label)})'
                 )
                 continue
+            if isinstance(label, dict):
+                # validate the shape of the dictionary
+                label_keys = set(label.keys())
+                if valid_keys - label_keys:
+                    errors.append(
+                        f"Label is missing required keys: {list(valid_keys - label_keys)}. Given: {label}"
+                    )
+                    continue
+
+                if label_keys - valid_keys:
+                    errors.append(
+                        f"Label has extra keys: {list(label_keys - valid_keys)}. Given: {label}"
+                    )
+                    continue
+
+                # validate the types of the inputs
+                label_name = label["name"]
+                label_value = label["value"]
+            else:
+                # no need to validate the shape of a dataclass
+                label_name = label.name
+                label_value = label.value
 
-            if label_keys - valid_keys:
+            if not isinstance(label_name, str):
                 errors.append(
-                    f"Label has extra keys: {list(label_keys - valid_keys)}. Given: {label}"
+                    f'Invalid label name "{label_name}"! Must be a string. Given {type(label_name)}'
+                )
+                continue
+            if not isinstance(label_value, str):
+                errors.append(
+                    f'Invalid label value "{label_value}"! Must be a string. Given {type(label_value)}'
                 )
                 continue
 
-            # validate the types of the inputs
-            label_name = label["name"]
-            label_value = label["value"]
-        else:
-            # no need to validate the shape of a dataclass
-            label_name = label.name
-            label_value = label.value
-
-        if not isinstance(label_name, str):
-            errors.append(
-                f'Invalid label name "{label_name}"! Must be a string. Given {type(label_name)}'
-            )
-            continue
-        if not isinstance(label_value, str):
-            errors.append(
-                f'Invalid label value "{label_value}"! Must be a string. Given {type(label_value)}'
-            )
-            continue
-
-        # validate the characters used in the inputs
-        if label_name_reg.match(label_name) is None:
-            errors.append(
-                f'Invalid label name "{label_name}"! Expected pattern: "{label_name_reg.pattern}"'
-            )
-            continue
-        if label_value_reg.match(label_value) is None:
-            errors.append(
-                f'Invalid label value "{label_value}"! Expected pattern: "{label_value_reg.pattern}"'
-            )
-            continue
+            # validate the characters used in the inputs
+            if label_name_reg.match(label_name) is None:
+                errors.append(
+                    f'Invalid label name "{label_name}"! Expected pattern: "{label_name_reg.pattern}"'
+                )
+                continue
+            if label_value_reg.match(label_value) is None:
+                errors.append(
+                    f'Invalid label value "{label_value}"! Expected pattern: "{label_value_reg.pattern}"'
+                )
+                continue
 
-        # Validate character limits
-        if len(label_name) > LABEL_NAME_MAX_CHARACTER_LIMIT:
-            errors.append(
-                f"Invalid label_name length. Max limit is {LABEL_NAME_MAX_CHARACTER_LIMIT} characters"
-                f"label name: {label_name}"
-            )
-            continue
+            # Validate character limits
+            if len(label_name) > LABEL_NAME_MAX_CHARACTER_LIMIT:
+                errors.append(
+                    f"Invalid label_name length. Max limit is {LABEL_NAME_MAX_CHARACTER_LIMIT} characters"
+                    f"label name: {label_name}"
+                )
+                continue
 
-        if len(str(label_value)) > LABEL_VALUE_MAX_CHARACTER_LIMIT:
-            errors.append(
-                f"Invalid label_value length. Max limit is {LABEL_VALUE_MAX_CHARACTER_LIMIT} characters"
-                f"label value: {label_value}"
-            )
-            continue
-    if errors:
-        error_msg = "\n".join(errors)
-        raise ValueError(f"Invalid label(s).  Errors:\n{error_msg}")
+            if len(str(label_value)) > LABEL_VALUE_MAX_CHARACTER_LIMIT:
+                errors.append(
+                    f"Invalid label_value length. Max limit is {LABEL_VALUE_MAX_CHARACTER_LIMIT} characters"
+                    f"label value: {label_value}"
+                )
+                continue
+        if errors:
+            error_msg = "\n".join(errors)
+            raise ValueError(f"Invalid label(s).  Errors:\n{error_msg}")
     return True
 
 
 def validate_string_is_trimmed(value: Any) -> bool:
     """Validates that the given value has no leading or trailing whitespace
 
     If the given value is not a string, its `str()` representation is checked instead.
```

## ts_sdk/task/run_reuse_loop.py

```diff
@@ -1,10 +1,12 @@
 import multiprocessing
 import os
+import shutil
 import sys
+import tempfile
 import traceback
 from threading import Timer
 
 from .__task_script_runner import run
 from .__util_log import Log
 from .__util_task import (
     ContainerStoppedException,
@@ -55,23 +57,28 @@
 
     healtcheck_timer = Timer(60.0, healtcheck_worker, [run_state])
     run_state["healtcheck_timer"] = healtcheck_timer
     healtcheck_timer.start()
 
 
 def task_process_fn(task, shared_dict):
+    task_tmp_dir = tempfile.mkdtemp()
+    os.environ.update({"TMPDIR": task_tmp_dir})
+
     run_params = get_run_params(task)
     sys.path.append(run_params.get("func_dir"))
     try:
         shared_dict["result"] = run(**run_params)
     except:
         e = sys.exc_info()[1]
         log.log(log.generate_error(e))
         shared_dict["error"] = traceback.format_exc()
-    sys.path.remove(run_params.get("func_dir"))
+    finally:
+        sys.path.remove(run_params.get("func_dir"))
+        shutil.rmtree(task_tmp_dir, ignore_errors=True)
 
 
 def main():
     manager = multiprocessing.Manager()
 
     shared_dict = manager.dict({"result": None, "error": None})
     run_state = {"task_process": None, "task": None, "healtcheck_timer": None}
```

## Comparing `ts_sdk-2.0.0rc4.dist-info/LICENSE.txt` & `ts_sdk-2.0.0rc5.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `ts_sdk-2.0.0rc4.dist-info/METADATA` & `ts_sdk-2.0.0rc5.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: ts-sdk
-Version: 2.0.0rc4
+Version: 2.0.0rc5
 Summary: Tetrascience Python SDK
 Home-page: https://developers.tetrascience.com
 Author: tetrascience
 Author-email: developers@tetrascience.com
 License: Apache License 2.0
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
@@ -198,14 +198,18 @@
 
 ## Changelog
 
 ### v2.0.0
 
 - Secure mode + bug fixes
 
+### v1.4.2
+
+- upgrade `smart_open` (`v4.2.0` &rarr; `v6.3.0`)
+
 ### v1.4.1
 
 - Make `allowedIDS` non-mandatory for task-script, to maintain backward compatibility
 
 ### v1.4.0
 
 - Added functionality to support `allowedIds` feature
```

## Comparing `ts_sdk-2.0.0rc4.dist-info/RECORD` & `ts_sdk-2.0.0rc5.dist-info/RECORD`

 * *Files 8% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 __tests__/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 __tests__/unit/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-__tests__/unit/test_allowed_ids.py,sha256=cK1iwSg0AKXqkHmkWINmwfgQeXk4hFilGFILoOWjz6s,4709
-__tests__/unit/test_cli_put.py,sha256=Yw2ghUNcKM6CUPswHu2hOyNJOokerCFQxuOKm4xT7Zo,1471
+__tests__/unit/test_allowed_ids.py,sha256=hJX4S-F9-pB3DTv5R4TxOAEb_grBB7EJC31dShAD8YQ,4810
+__tests__/unit/test_cli_put.py,sha256=gvFJnl5KOj2U5ixJecPJ16QOHUTLIv9c-LKN_NM4-TQ,2945
 __tests__/unit/test_command.py,sha256=VgE74_qS0Z1oI5C8eWWOZiqEc2YtLJ2X8lmSeeGs2ps,2466
-__tests__/unit/test_context.py,sha256=KOteAaU6lVpni7QojvZy1eC1uMPdMg3qLTicWU7VxDw,31533
+__tests__/unit/test_context.py,sha256=neCM_h1D5koCWd_pZIS1hCUCEtUdRnd7robNhIgNQHg,36619
 __tests__/unit/test_datalake.py,sha256=Srzx3aFP-Wzq4OH8hfEqbOxGglF25PApOA9nSswfG30,9218
 __tests__/unit/test_encoders.py,sha256=khTLbG2fGxQ8QWAz1QPoKOMukVwQt7muYrpcIgYdjNk,1628
 __tests__/unit/test_es_datalake.py,sha256=ehcEk1sAJ4acCbscZ96F9hlk2F2R8SsieQkCY_joJMQ,2161
-__tests__/unit/test_fileinfo.py,sha256=P8BHkbsr4r66BbazpsAaWj95Qy3JJ9TXlPB4n2KI1aU,4307
+__tests__/unit/test_fileinfo.py,sha256=vGeyfX3in8RqYu8YMiuPgZtN8SdnIh-US19VgBQ1Q0U,5153
 __tests__/unit/test_merge.py,sha256=20ouaoGHAaa_ZFZnP7wSD85rUfAxKIQO7FEd3KJc9-g,939
 __tests__/unit/test_run_reuse.py,sha256=UXsElAzCb0tv3EapomK7_HQj0HlxrXw9LVKADtlOJuc,1200
 __tests__/unit/test_task.py,sha256=fxXZPPwf2hCfF2IUnUbNwe_mWnzvrSQoLKfX-H_7XSk,3552
 __tests__/unit/test_taskdev.py,sha256=UFfYcXZe-wyuwFu0B8oMffuLRhgQD4y0dBxGCQrELgc,660
 __tests__/unit/test_util_log.py,sha256=iHumUe1I84tqXZOxZ03IHrm7pV-M-g3Y03Lr_O5GXAQ,13747
-__tests__/unit/test_util_validation.py,sha256=AIdnd9dS0XEZIJU_4P7DwE-0qr95p-q8cGOEfY7biXo,7328
+__tests__/unit/test_util_validation.py,sha256=quApe2800VWIGjrJi0LSOD2ipgVjHtUbA_yB1AjDbO0,7639
 __tests__/unit/test_versioned_ref.py,sha256=p9JWlsdi4yOFUcvwdldrp0xmHDNY2b4rA06QsfGSba8,1091
 __tests__/unit/task/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 __tests__/unit/task/test_decorators.py,sha256=hJa_Zpo1VZSPRIcFr90n0WkRfjbNQsTH4O61GG5BMwY,1149
 __tests__/unit/task/adapters/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 __tests__/unit/task/adapters/test_adapters.py,sha256=xFrHEQbolhmTV1Qcmx2BPqAleP1dutYOK9exIhmh8M0,4988
 __tests__/unit/task/adapters/test_curry_version.py,sha256=pIFulrbgGE7TY29LSp2A6qy64sshhkJko8XlvJDfneE,1329
 __tests__/unit/task/adapters/test_platform_version.py,sha256=VZ4di9K_XsWS_oVU1R1Qevv1z8Jltjdu9xsJiBM2Dys,2625
@@ -26,15 +26,15 @@
 __tests__/unit/task/snapshots/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 __tests__/unit/task/snapshots/snap_test_util_log.py,sha256=gITqejHhyjHuR-oewHqu652w08x7vECPUyaer4MGNT0,2563
 ts_sdk/__init__.py,sha256=nW3hhHa0VXalkQ_nkC7MJZFlXxtUU23y4kzmY5knKDI,183
 ts_sdk/cli/__api.py,sha256=Lfv_vvEbWP2XSFrOwyspjDfbYndUSneguDA0FowTI30,2877
 ts_sdk/cli/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ts_sdk/cli/__init_cmd.py,sha256=b68Y2jj8hswt4zVVuXRfTeCcZKpUJ9bT6xm8iuD1Zdc,2173
 ts_sdk/cli/__main__.py,sha256=uLT-EQeIDK4hWVcyqoPlIc9kUXMi7re4G3Q6t90MKv0,1188
-ts_sdk/cli/__put_cmd.py,sha256=5uK1eQLiEdQj9T8aQMVkRvSCjMgSTMgKXkvYfovQRpA,7681
+ts_sdk/cli/__put_cmd.py,sha256=7J2YGMcbFS19U_7j_36oPjVrHxXj-IKQhYNzRzOIJzY,7736
 ts_sdk/cli/__utils.py,sha256=Amso60XjV6Xcp88xFfeiJECgYyYDXqSLFa7JUi9nZ60,2442
 ts_sdk/cli/protocol-template/protocol/README.md.template,sha256=kQVoY4ZZLCWzNf-FWKcEHsOFgHSggOfQJ7s6FeEL_1U,63
 ts_sdk/cli/protocol-template/protocol/protocol.json.template,sha256=lgeY93c-nBR5je77Av30qamRHDrkpGvLOYx83X-9wW4,712
 ts_sdk/cli/protocol-template/protocol/script.js.template,sha256=sVcVw4PjyH5mY4331zY1K2ojzDi3UjcozNc3pWYLJeA,874
 ts_sdk/cli/protocol-template/task-script/Pipfile,sha256=fZJ9MD_ucna9CXbgIMJvEN-JY2forb1M60X3GtB1G1o,246
 ts_sdk/cli/protocol-template/task-script/README.md.template,sha256=0YC5Sz45QIOUh-uUWEX7aQFNzXKMTrDry_Bypw6xJpU,72
 ts_sdk/cli/protocol-template/task-script/config.json,sha256=8dwX5bfwKcsLNI7MJ0EI3QDUChIpU_sgfhu7Fdb9LFE,113
@@ -46,33 +46,33 @@
 ts_sdk/cli/protocol-template/task-script/__test__/data/input.json,sha256=vC2--qSInGtvuqEaFKeHbh5_wPCjlLu_Zzio6kb5htY,15
 ts_sdk/cli/put_cmd_helpers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 ts_sdk/cli/put_cmd_helpers/upload_validator.py,sha256=DD0PD1hfUv0wt98JrGB7mt7Qc7BHAtd2mAbTzKwpIs4,1740
 ts_sdk/schemas/__init__.py,sha256=XhOqGgIa1_QACmJ4KfzZ6BpSI3CvUHvXnXOntBQSnXk,270
 ts_sdk/schemas/config.schema.json,sha256=lstvMB4_72lQy44AnPcBjnBaj_kfgL71chAg6AdUaKs,1766
 ts_sdk/schemas/protocol.schema.json,sha256=oekvLAMDHjQ0FUzPbkdTrATKgHc7cRbirQ9e6GBnwg8,2206
 ts_sdk/task/__init__.py,sha256=KclRzrz_C6reEoQEUIX8Xx0RcYLVDTwtfmfhXyd_1dk,104
-ts_sdk/task/__task_script_runner.py,sha256=Phr66VCsr5Ddqhgb1_Xxh9bCAb--PaWX81we5quZcZs,25471
+ts_sdk/task/__task_script_runner.py,sha256=DzrnDhLSLwsrirJv5K0xjpJf2Z6XNLCWJdUG20CaP7Q,27651
 ts_sdk/task/__util_command.py,sha256=jcWz-ZwVb8fRyZjhyw0RoigdcJPiYp3kiGqcPQ1YSNE,3317
-ts_sdk/task/__util_config.py,sha256=E5LqtMROce80LrRGe1oOzL1n1SVaa1XMPEZCoB52eNI,6782
-ts_sdk/task/__util_datalake.py,sha256=zFsP6mQCxDlDiPsrXoelwTrcgTREyW76tm7Qr9zB8_w,28789
-ts_sdk/task/__util_decorators.py,sha256=SbXRst050JS24yRJcXv6V2z5E_fwgKRJEIIQtZKEEjQ,1252
+ts_sdk/task/__util_config.py,sha256=dBwgeRdiqIdBY7cOYdoxwZT7bDyfbBg9BbIgGGdu_gg,6998
+ts_sdk/task/__util_datalake.py,sha256=bBhhW64ELz_iqjfGbRGt2mHESjgFi4zVlksMBP4gxC8,28883
+ts_sdk/task/__util_decorators.py,sha256=uD2oLfuS5Z15_Ma_O3on0StS5eLf57wPNS-eztLQvI0,1613
 ts_sdk/task/__util_es_datalake.py,sha256=DXVxpPDQ4p7eD9c_Jpo2X_mMS5qE6KIA1yqIyeaARWo,1714
-ts_sdk/task/__util_fileinfo.py,sha256=fqmen0ZNGZHsPWPOcmpMumAOCm-WNnm_cZ2q0vfZQik,5630
+ts_sdk/task/__util_fileinfo.py,sha256=5aW-cBTX2PJSphK_ST9Eu5dA9oxBV3XBDTWNtYgKeHA,5685
 ts_sdk/task/__util_ids.py,sha256=1Cj0qOvu08BPrUKdhgExsX6nO-Azh1GzojpP3BHOprE,2221
 ts_sdk/task/__util_log.py,sha256=nG-Hz24vst5LPpfGS51C1CHMQepEpk7RmHQ5hpdHkzA,8334
 ts_sdk/task/__util_merge.py,sha256=jcs37uGHWsYrQ_Y3qhw03N1TDXZJGdZBRswtMePyOg4,917
 ts_sdk/task/__util_metadata.py,sha256=UKcPt5TzTiIJHaprDIsnRwZ5mxHuws3mHHYQ6Hb0_X0,1483
 ts_sdk/task/__util_storage.py,sha256=6EYpMZltljkeRTAyX5c2xTeoU0hT6KDCGz1o-0FkvXw,827
-ts_sdk/task/__util_validation.py,sha256=2ecYMNXKPpVyR_PpvN3SKTI8sZZhZETEeKZekxo65kg,5534
+ts_sdk/task/__util_validation.py,sha256=_2-68WKrgP5T5R2GGlDJS9BWzfHMSeqA4tz1Zc3RYOQ,6429
 ts_sdk/task/__util_versioned_ref.py,sha256=O7N55uDbe3roTeJuHXlsN0-wnL9ObrWa1bLR2-MUOVU,1391
 ts_sdk/task/__validate_config.py,sha256=_LtP5TcNypl_ieUvLRaOUYAhnexdFULF8jx557fGMmE,677
 ts_sdk/task/data_model.py,sha256=mTQmmvBylU9GEBedFmsqHfczT4LCte_ymDGIVwyqRrw,1925
 ts_sdk/task/encoders.py,sha256=GTx9s6TFAVdGpmdxZOpWsJUxr0y-wHud8xHc3la5lEA,669
 ts_sdk/task/run.py,sha256=_tJr5TU-ftJADPKQwrEtBpcwW5tBM2Nt8-cImgsHB9Q,1742
-ts_sdk/task/run_reuse_loop.py,sha256=HquVBk1D0zFoYFzbWg2swzvByAR4hfcVF-gVbpmStP0,5183
+ts_sdk/task/run_reuse_loop.py,sha256=aoTBWlqczBMtoQujltqI2LoyRw5uoD6Z1o_G9EIZv9w,5373
 ts_sdk/task/__util_adapters/__init__.py,sha256=DfIcsDeuKc8Mr29G2U_M8ZM9O0Ct_YmfAALqBmY0JKI,295
 ts_sdk/task/__util_adapters/communication_format.py,sha256=QaLxrBBXn6lWey6EiBtlnDbfoJ1ZFwUzukcliKry8Lc,2175
 ts_sdk/task/__util_adapters/curry_format.py,sha256=5TprjJXc4ZQ2MHAfKpkiLawF2VwEw94HybAHi7RvtFo,656
 ts_sdk/task/__util_adapters/endpoint_adapter.py,sha256=kUN-W7ZVfGO04bR_HvUbvY5VQHkHsJpX2xU9i7gxQJQ,1193
 ts_sdk/task/__util_adapters/make_adapter.py,sha256=2ycjnKDolmz_0V0-_gocSkZDhT0XTjFJQeyiSA66Djk,2892
 ts_sdk/task/__util_task/__init__.py,sha256=elBbN-P0Z25fbTkRdn0Sjpv61A2SBx9OrtziWX1u_AE,4657
 ts_sdk/task/__util_task/exceptions.py,sha256=nderu3F6DU779TmqAh2bRRzypaasXNnQCg_ViF7jMEQ,108
@@ -80,13 +80,13 @@
 ts_sdk/task/log_codes/log_code.py,sha256=w_XOMUKLAVGvJuo64_rp3sVFvqodqoyR0X1jblm2EOM,178
 ts_sdk/task/log_codes/log_code_collection.py,sha256=C6zxV4dfDXrslSRa0sXjSjRTUQcIHw_V-l5eFNXfJZU,1831
 ts_sdk/task/log_codes/log_code_collection_meta.py,sha256=25Gtn2hj9T1Nz6Gho2I5F25sF5LgR2wTneq25E625nY,4348
 ts_sdk/task/log_codes/log_code_validator.py,sha256=DybVQKuRjZXPG_vO5ELRmgVVwfzk98jPolklv-ukY-8,1967
 ts_sdk/taskdev/__init__.py,sha256=6ebaD6iBs5TX9NQ_4-GaEKY36wtfO0OseUwtlysUrUE,106
 ts_sdk/taskdev/context.py,sha256=iGF8eAcIaamCQ2QOKj8ANQ8qH4wiVtktqc7fHSbjRCQ,5255
 ts_sdk/taskdev/testing.py,sha256=U_uRW-5ie8zQNmgeHNSIvtem-Nj_fqdSit7TccpowMI,1502
-ts_sdk-2.0.0rc4.dist-info/LICENSE.txt,sha256=FC8uIvMLb-xkNvwGshtXfs5RofD-2-wnhE-dmpU12I8,11370
-ts_sdk-2.0.0rc4.dist-info/METADATA,sha256=OZsSkQK3nMwPGYyfbMuQWJ1KnGzZeO4UWjI0ddttzYA,8636
-ts_sdk-2.0.0rc4.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-ts_sdk-2.0.0rc4.dist-info/entry_points.txt,sha256=d-rCROmr7Jbp7WkB62VQhU2X1ygWcL4kuwWOdciRvH8,52
-ts_sdk-2.0.0rc4.dist-info/top_level.txt,sha256=ACdEe6bsMwpkGW5IM2T4f-kj-_RL-k2YG1Rn2TJfhkU,17
-ts_sdk-2.0.0rc4.dist-info/RECORD,,
+ts_sdk-2.0.0rc5.dist-info/LICENSE.txt,sha256=FC8uIvMLb-xkNvwGshtXfs5RofD-2-wnhE-dmpU12I8,11370
+ts_sdk-2.0.0rc5.dist-info/METADATA,sha256=jgMYUISja96B60a2didfxRXCBpZE2sltsSeVBT_gLho,8699
+ts_sdk-2.0.0rc5.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+ts_sdk-2.0.0rc5.dist-info/entry_points.txt,sha256=d-rCROmr7Jbp7WkB62VQhU2X1ygWcL4kuwWOdciRvH8,52
+ts_sdk-2.0.0rc5.dist-info/top_level.txt,sha256=ACdEe6bsMwpkGW5IM2T4f-kj-_RL-k2YG1Rn2TJfhkU,17
+ts_sdk-2.0.0rc5.dist-info/RECORD,,
```

